{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a7484cc-6b31-4d27-b17b-b3a89569d6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d636a47a-cebf-438a-b29b-ba467c0900eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3 10000 2 2 100 2 1\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Running BENN\")\n",
    "parser.add_argument('--model1', default=5, type = int, help = 'model1')\n",
    "parser.add_argument('--model2', default=3, type = int, help = 'model2')\n",
    "parser.add_argument('--n', default=10000, type = int, help = 'n')\n",
    "parser.add_argument('--m', default=2, type = int, help = 'm')\n",
    "parser.add_argument('--l2', default=2, type = int, help = 'l2')\n",
    "parser.add_argument('--r2', default=100, type = int, help = 'r2')\n",
    "parser.add_argument('--d', default=2, type = int, help = 'd')\n",
    "parser.add_argument('--t', default=1, type = int, help = 't')\n",
    "args = parser.parse_args()\n",
    "model1 = args.model1\n",
    "model2 = args.model2\n",
    "n = args.n\n",
    "m = args.m\n",
    "l2 = args.l2\n",
    "r2 = args.r2\n",
    "res_d = args.d\n",
    "t = args.t\n",
    "print(model1, model2, n, m, l2, r2, res_d, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50359073-4520-42d2-bcc6-63ce3e3ca145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1fd3b09-e12c-4172-973e-11a56a2d1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"./results-BENN-linear/result-\" + str(model1) + \"-\" + str(model2) + \"-\" + str(m) + \"-\" + str(n)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "104928d9-de5e-497b-8ee8-4c99e5b8e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/x_train_\" + str(t) + \".csv\")\n",
    "x_train=x_train.drop('Unnamed: 0', axis=1)\n",
    "y_train=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/y_train_\" + str(t) + \".csv\")\n",
    "y_train=y_train.drop('Unnamed: 0', axis=1)\n",
    "x_test=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/x_test_\" + str(t) + \".csv\")\n",
    "x_test=x_test.drop('Unnamed: 0', axis=1)\n",
    "y_test=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/y_test_\" + str(t) + \".csv\")\n",
    "y_test=y_test.drop('Unnamed: 0', axis=1)\n",
    "z_test=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/z_test_\" + str(t) + \".csv\")\n",
    "z_test=z_test.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "n=x_train.shape[0]\n",
    "p=x_train.shape[1]\n",
    "#res_d=1\n",
    "\n",
    "\n",
    "x_train = torch.tensor(x_train.values).to(torch.float)\n",
    "x_test = torch.tensor(x_test.values).to(torch.float)\n",
    "if m==1:\n",
    "    y_train = torch.tensor(y_train.values).to(torch.float)\n",
    "    y_test = torch.tensor(y_test.values).to(torch.float)\n",
    "else:\n",
    "    y_trans_train = (y_train - y_train.mean()) / y_train.std()\n",
    "    y_trans_test = (y_test - y_train.mean()) / y_train.std()\n",
    "    for i in range(2,m+1):\n",
    "        y_train_intermediate=y_train**i/math.factorial(i)\n",
    "        mean_inter = y_train_intermediate.mean()\n",
    "        sd_inter = y_train_intermediate.std()\n",
    "        y_train_intermediate = (y_train_intermediate - mean_inter) / sd_inter\n",
    "        y_trans_train = np.concatenate((y_trans_train,y_train_intermediate), axis=1)\n",
    "        y_test_intermediate=y_test**i/math.factorial(i)\n",
    "        y_test_intermediate = (y_test_intermediate - mean_inter) / sd_inter\n",
    "        y_trans_test = np.concatenate((y_trans_test,y_test_intermediate), axis=1)\n",
    "    y_train = torch.tensor(y_trans_train).to(torch.float)\n",
    "    y_test = torch.tensor(y_trans_test).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e0c665f-c218-4553-96f8-80fd29f1114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.01987 | Test loss: 0.95573\n",
      "Current Time = 16:48:16\n",
      "Epoch: 25 | Loss: 0.98701 | Test loss: 0.94213\n",
      "Current Time = 16:48:16\n",
      "Epoch: 50 | Loss: 0.97656 | Test loss: 0.93355\n",
      "Current Time = 16:48:16\n",
      "Epoch: 75 | Loss: 0.96437 | Test loss: 0.92457\n",
      "Current Time = 16:48:16\n",
      "Epoch: 100 | Loss: 0.95239 | Test loss: 0.91518\n",
      "Current Time = 16:48:16\n",
      "Epoch: 125 | Loss: 0.94154 | Test loss: 0.90667\n",
      "Current Time = 16:48:16\n",
      "Epoch: 150 | Loss: 0.93189 | Test loss: 0.89879\n",
      "Current Time = 16:48:16\n",
      "Epoch: 175 | Loss: 0.92478 | Test loss: 0.89340\n",
      "Current Time = 16:48:17\n",
      "Epoch: 200 | Loss: 0.92094 | Test loss: 0.89125\n",
      "Current Time = 16:48:17\n",
      "Epoch: 225 | Loss: 0.91914 | Test loss: 0.89157\n",
      "Current Time = 16:48:17\n",
      "Epoch: 250 | Loss: 0.91836 | Test loss: 0.89231\n",
      "Current Time = 16:48:17\n",
      "Epoch: 275 | Loss: 0.91783 | Test loss: 0.89310\n",
      "Current Time = 16:48:17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(x_train[:5],y_trans[:5])\n",
    "mse_loss = nn.MSELoss()\n",
    "# Build model\n",
    "class nn_dr_reg_model(nn.Module):\n",
    "    def __init__(self, input_features, output_features, dim_red_features, hidden_units_e, ens_reg_layers):\n",
    "        super().__init__()\n",
    "        model_dim_red=[]\n",
    "        model_dim_red.append(nn.Linear(in_features=input_features, \n",
    "                                    out_features=dim_red_features))\n",
    "        self.dim_red_layer_stack = nn.Sequential(*model_dim_red)\n",
    "\n",
    "        model_ens_reg=[]\n",
    "        model_ens_reg.append(nn.Linear(in_features=dim_red_features, out_features=hidden_units_e))\n",
    "        model_ens_reg.append(nn.ReLU())\n",
    "        for i in range(1,ens_reg_layers):\n",
    "            model_ens_reg.append(nn.Linear(in_features=hidden_units_e, out_features=hidden_units_e))\n",
    "            model_ens_reg.append(nn.ReLU())\n",
    "        model_ens_reg.append(nn.Linear(in_features=hidden_units_e, out_features=output_features))\n",
    "        self.ens_reg_layer_stack = nn.Sequential(*model_ens_reg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        suff_predictor = self.dim_red_layer_stack(x)\n",
    "        ens_output = self.ens_reg_layer_stack(suff_predictor)\n",
    "        return ens_output, suff_predictor\n",
    "\n",
    "\n",
    "# Create an instance of BlobModel and send it to the target device\n",
    "model_nn = nn_dr_reg_model(input_features=p, \n",
    "                        output_features=m, \n",
    "                        dim_red_features=res_d, \n",
    "                        hidden_units_e=r2,\n",
    "                        ens_reg_layers=l2\n",
    "                        ).to(device)\n",
    "model_nn\n",
    "optimizer = torch.optim.Adam(model_nn.parameters(), \n",
    "                            lr=0.001)\n",
    "epochs = 300\n",
    "x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_nn.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_pred_train, y_suff_train = model_nn(x_train) \n",
    "\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = mse_loss(y_pred_train, y_train) \n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_nn.eval()\n",
    "\n",
    "    y_pred_test, y_suff_test = model_nn(x_test)\n",
    "    loss_test = mse_loss(y_pred_test, y_test) \n",
    "    #corr_test = max(abs(stats.pearsonr(np.float64(y_suff_test.detach().numpy()[:,1]),np.float64(z_test.to_numpy()[:,1])).statistic),\n",
    "    #                abs(stats.pearsonr(np.float64(y_suff_test.detach().numpy()[:,0]),np.float64(z_test.to_numpy()[:,1])).statistic))\n",
    "\n",
    "    if epoch % 25 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Test loss: {loss_test:.5f}\")\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(\"Current Time =\", current_time)\n",
    "model_nn.eval()\n",
    "with torch.inference_mode():\n",
    "    y_pred_test, y_suff_test = model_nn(x_test)\n",
    "y_suff_test=y_suff_test.numpy()\n",
    "#if res_d==2:\n",
    "#    corr_current=[abs(stats.pearsonr(np.float64(y_suff_test[:,0]),np.float64(z_test.to_numpy()[:,0])).statistic),\n",
    "#                  abs(stats.pearsonr(np.float64(y_suff_test[:,0]),np.float64(z_test.to_numpy()[:,1])).statistic),\n",
    "#                  abs(stats.pearsonr(np.float64(y_suff_test[:,1]),np.float64(z_test.to_numpy()[:,0])).statistic),\n",
    "#                  abs(stats.pearsonr(np.float64(y_suff_test[:,1]),np.float64(z_test.to_numpy()[:,1])).statistic)]\n",
    "#corr_list.append(corr_current)\n",
    "#print(model1, model2, t, corr_current)\n",
    "#corr_list_df=pd.DataFrame(corr_list)\n",
    "#corr_list_df.to_csv(\"./results-BENN-linear/result-\" + str(model1) + \"-\" + str(model2) + \"-\" + str(m) + \"-\" + str(n) + \".csv\")\n",
    "#print(model1, model2, np.mean(corr_list), np.std(corr_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3db139c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_suff_test_df=pd.DataFrame(y_suff_test)\n",
    "y_suff_test_df.to_csv(\"./results-BENN-linear/result-\" + str(model1) + \"-\" + str(model2) + \"-\" + str(m) + \"-\" + str(n) + \"/y_suff_\" + str(t) + \".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "548afea9-f5c5-4fa5-a476-57affbae7fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.9085233184655316\n",
      "coefficient of determination: 0.9786804172692043\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.linear_model import LinearRegression\n",
    "#model=LinearRegression()\n",
    "#x=y_suff_test\n",
    "#y=z_test.to_numpy()[:,0]\n",
    "#model.fit(x, y)\n",
    "#r_sq1 = model.score(x, y)\n",
    "#print(f\"coefficient of determination: {r_sq1}\")\n",
    "#model=LinearRegression()\n",
    "#x=y_suff_test\n",
    "#y=z_test.to_numpy()[:,1]\n",
    "#model.fit(x, y)\n",
    "#r_sq2 = model.score(x, y)\n",
    "#print(f\"coefficient of determination: {r_sq2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bde6300-5115-407e-882f-9d834941dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r_sq=[r_sq1,r_sq2]\n",
    "#r_sq_df=pd.DataFrame(r_sq)\n",
    "#r_sq_df.to_csv(\"./results-BENN-linear/result-\" + str(model1) + \"-\" + str(model2) + \"-\" + str(m) + \"-\" + str(n) + \"/r_sq_\" + str(t) + \".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e72e0db-af2d-4c00-85e1-2f69f8be9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dcor.distance_correlation(np.float64(y_suff_test.detach().numpy()),np.float64(z_test.to_numpy()),method=\"naive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18051330-bc5c-40fc-b40f-2e3ec8b75f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(y_suff_test[:,0],z_test.to_numpy()[:,1],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb29d492-c748-480e-8324-34bee302903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(z_test.to_numpy()[:,0],z_test.to_numpy()[:,1],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d604b58-58ce-460b-84ec-468bc2a5a8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch_conda",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
