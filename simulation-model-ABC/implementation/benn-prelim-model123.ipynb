{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7484cc-6b31-4d27-b17b-b3a89569d6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "\n",
    "import dcor\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d636a47a-cebf-438a-b29b-ba467c0900eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 5000 1 4 4 300 300 1 1\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Running BENN\")\n",
    "parser.add_argument('--model1', default=2, type = int, help = 'model1')\n",
    "parser.add_argument('--model2', default=1, type = int, help = 'model2')\n",
    "parser.add_argument('--n', default=5000, type = int, help = 'n')\n",
    "parser.add_argument('--m', default=1, type = int, help = 'm')\n",
    "parser.add_argument('--l1', default=4, type = int, help = 'l1')\n",
    "parser.add_argument('--l2', default=4, type = int, help = 'l2')\n",
    "parser.add_argument('--r1', default=300, type = int, help = 'r1')\n",
    "parser.add_argument('--r2', default=300, type = int, help = 'r2')\n",
    "parser.add_argument('--d', default=1, type = int, help = 'd')\n",
    "parser.add_argument('--t', default=1, type = int, help = 't')\n",
    "args = parser.parse_args([])\n",
    "model1 = args.model1\n",
    "model2 = args.model2\n",
    "n = args.n\n",
    "m = args.m\n",
    "l1 = args.l1\n",
    "l2 = args.l2\n",
    "r1 = args.r1\n",
    "r2 = args.r2\n",
    "res_d = args.d\n",
    "t = args.t\n",
    "print(model1, model2, n, m, l1, l2, r1, r2, res_d, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50359073-4520-42d2-bcc6-63ce3e3ca145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0c665f-c218-4553-96f8-80fd29f1114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 4.88627 | Test Loss: 4.46475\n",
      "Current Time = 12:38:25\n",
      "Epoch: 25 | Loss: 1.55305 | Test Loss: 1.34544\n",
      "Current Time = 12:38:26\n",
      "Epoch: 50 | Loss: 0.39593 | Test Loss: 0.51795\n",
      "Current Time = 12:38:28\n",
      "Epoch: 75 | Loss: 0.25271 | Test Loss: 0.40891\n",
      "Current Time = 12:38:29\n",
      "Epoch: 100 | Loss: 0.14702 | Test Loss: 0.37591\n",
      "Current Time = 12:38:30\n",
      "Epoch: 125 | Loss: 0.09483 | Test Loss: 0.41011\n",
      "Current Time = 12:38:31\n",
      "Epoch: 150 | Loss: 0.06051 | Test Loss: 0.44334\n",
      "Current Time = 12:38:32\n",
      "Epoch: 175 | Loss: 0.05313 | Test Loss: 0.48240\n",
      "Current Time = 12:38:33\n",
      "1 1 1 0.9456371261821748\n",
      "Epoch: 0 | Loss: 5.30345 | Test Loss: 4.72156\n",
      "Current Time = 12:38:35\n",
      "Epoch: 25 | Loss: 2.91308 | Test Loss: 2.92049\n",
      "Current Time = 12:38:36\n",
      "Epoch: 50 | Loss: 2.68975 | Test Loss: 2.60451\n",
      "Current Time = 12:38:37\n",
      "Epoch: 75 | Loss: 0.45436 | Test Loss: 0.61924\n",
      "Current Time = 12:38:38\n",
      "Epoch: 100 | Loss: 0.33057 | Test Loss: 0.45967\n",
      "Current Time = 12:38:39\n",
      "Epoch: 125 | Loss: 0.19868 | Test Loss: 0.36170\n",
      "Current Time = 12:38:41\n",
      "Epoch: 150 | Loss: 0.09101 | Test Loss: 0.37674\n",
      "Current Time = 12:38:42\n",
      "Epoch: 175 | Loss: 0.03955 | Test Loss: 0.41884\n",
      "Current Time = 12:38:43\n",
      "1 1 2 0.9492763555116088\n",
      "1 1 0.9474567408468918 0.0018196146647170286\n",
      "Epoch: 0 | Loss: 17.12998 | Test Loss: 14.00432\n",
      "Current Time = 12:38:44\n",
      "Epoch: 25 | Loss: 3.92040 | Test Loss: 2.40972\n",
      "Current Time = 12:38:45\n",
      "Epoch: 50 | Loss: 0.88806 | Test Loss: 0.92414\n",
      "Current Time = 12:38:47\n",
      "Epoch: 75 | Loss: 0.35942 | Test Loss: 0.52317\n",
      "Current Time = 12:38:48\n",
      "Epoch: 100 | Loss: 0.20935 | Test Loss: 0.45550\n",
      "Current Time = 12:38:49\n",
      "Epoch: 125 | Loss: 0.14049 | Test Loss: 0.47277\n",
      "Current Time = 12:38:50\n",
      "Epoch: 150 | Loss: 0.08208 | Test Loss: 0.51085\n",
      "Current Time = 12:38:51\n",
      "Epoch: 175 | Loss: 0.04582 | Test Loss: 0.54840\n",
      "Current Time = 12:38:52\n",
      "1 2 1 0.9729909950788564\n",
      "Epoch: 0 | Loss: 15.46260 | Test Loss: 17.02662\n",
      "Current Time = 12:38:54\n",
      "Epoch: 25 | Loss: 2.11718 | Test Loss: 2.34764\n",
      "Current Time = 12:38:55\n",
      "Epoch: 50 | Loss: 0.81375 | Test Loss: 0.93712\n",
      "Current Time = 12:38:56\n",
      "Epoch: 75 | Loss: 0.31858 | Test Loss: 0.56478\n",
      "Current Time = 12:38:57\n",
      "Epoch: 100 | Loss: 0.17775 | Test Loss: 0.46976\n",
      "Current Time = 12:38:58\n",
      "Epoch: 125 | Loss: 0.12543 | Test Loss: 0.47241\n",
      "Current Time = 12:39:00\n",
      "Epoch: 150 | Loss: 0.07709 | Test Loss: 0.49959\n",
      "Current Time = 12:39:01\n",
      "Epoch: 175 | Loss: 0.04759 | Test Loss: 0.52071\n",
      "Current Time = 12:39:02\n",
      "1 2 2 0.9833798649878466\n",
      "1 2 0.9781854300333515 0.005194434954495064\n",
      "Epoch: 0 | Loss: 64.97542 | Test Loss: 43.49755\n",
      "Current Time = 12:39:03\n",
      "Epoch: 25 | Loss: 27.03267 | Test Loss: 20.37181\n",
      "Current Time = 12:39:04\n",
      "Epoch: 50 | Loss: 5.18807 | Test Loss: 4.97416\n",
      "Current Time = 12:39:06\n",
      "Epoch: 75 | Loss: 1.64512 | Test Loss: 2.46434\n",
      "Current Time = 12:39:07\n",
      "Epoch: 100 | Loss: 0.69345 | Test Loss: 1.62813\n",
      "Current Time = 12:39:08\n",
      "Epoch: 125 | Loss: 0.39084 | Test Loss: 1.42009\n",
      "Current Time = 12:39:09\n",
      "Epoch: 150 | Loss: 0.25855 | Test Loss: 1.26149\n",
      "Current Time = 12:39:10\n",
      "Epoch: 175 | Loss: 0.26439 | Test Loss: 1.25423\n",
      "Current Time = 12:39:11\n",
      "1 3 1 0.9628990665242076\n",
      "Epoch: 0 | Loss: 55.74915 | Test Loss: 35.35765\n",
      "Current Time = 12:39:13\n",
      "Epoch: 25 | Loss: 28.69903 | Test Loss: 16.11307\n",
      "Current Time = 12:39:14\n",
      "Epoch: 50 | Loss: 4.59645 | Test Loss: 7.09509\n",
      "Current Time = 12:39:15\n",
      "Epoch: 75 | Loss: 1.55456 | Test Loss: 5.01229\n",
      "Current Time = 12:39:16\n",
      "Epoch: 100 | Loss: 0.63478 | Test Loss: 3.48379\n",
      "Current Time = 12:39:17\n",
      "Epoch: 125 | Loss: 0.42077 | Test Loss: 2.75072\n",
      "Current Time = 12:39:19\n",
      "Epoch: 150 | Loss: 0.25857 | Test Loss: 2.64278\n",
      "Current Time = 12:39:20\n",
      "Epoch: 175 | Loss: 0.20224 | Test Loss: 2.62011\n",
      "Current Time = 12:39:21\n",
      "1 3 2 0.9656285651531425\n",
      "1 3 0.9642638158386752 0.0013647493144674505\n",
      "Epoch: 0 | Loss: 1.10252 | Test Loss: 1.02965\n",
      "Current Time = 12:39:22\n",
      "Epoch: 25 | Loss: 0.86141 | Test Loss: 0.90205\n",
      "Current Time = 12:39:23\n",
      "Epoch: 50 | Loss: 0.50394 | Test Loss: 0.46375\n",
      "Current Time = 12:39:24\n",
      "Epoch: 75 | Loss: 0.25660 | Test Loss: 0.36452\n",
      "Current Time = 12:39:26\n",
      "Epoch: 100 | Loss: 0.18739 | Test Loss: 0.33222\n",
      "Current Time = 12:39:27\n",
      "Epoch: 125 | Loss: 0.13072 | Test Loss: 0.36425\n",
      "Current Time = 12:39:28\n",
      "Epoch: 150 | Loss: 0.11610 | Test Loss: 0.38239\n",
      "Current Time = 12:39:29\n",
      "Epoch: 175 | Loss: 0.06413 | Test Loss: 0.43228\n",
      "Current Time = 12:39:30\n",
      "2 1 1 0.532957609361277\n",
      "Epoch: 0 | Loss: 1.05819 | Test Loss: 0.94942\n",
      "Current Time = 12:39:32\n",
      "Epoch: 25 | Loss: 0.82442 | Test Loss: 0.78785\n",
      "Current Time = 12:39:33\n",
      "Epoch: 50 | Loss: 0.46569 | Test Loss: 0.51950\n",
      "Current Time = 12:39:34\n",
      "Epoch: 75 | Loss: 0.22205 | Test Loss: 0.33648\n",
      "Current Time = 12:39:35\n",
      "Epoch: 100 | Loss: 0.12076 | Test Loss: 0.34528\n",
      "Current Time = 12:39:36\n",
      "Epoch: 125 | Loss: 0.05348 | Test Loss: 0.39488\n",
      "Current Time = 12:39:38\n",
      "Epoch: 150 | Loss: 0.01960 | Test Loss: 0.43407\n",
      "Current Time = 12:39:39\n",
      "Epoch: 175 | Loss: 0.00769 | Test Loss: 0.44574\n",
      "Current Time = 12:39:40\n",
      "2 1 2 0.8235710821226292\n",
      "2 1 0.678264345741953 0.1453067363806761\n",
      "Epoch: 0 | Loss: 4.93938 | Test Loss: 4.36505\n",
      "Current Time = 12:39:41\n",
      "Epoch: 25 | Loss: 0.69989 | Test Loss: 1.01236\n",
      "Current Time = 12:39:42\n",
      "Epoch: 50 | Loss: 0.43487 | Test Loss: 0.59608\n",
      "Current Time = 12:39:43\n",
      "Epoch: 75 | Loss: 0.26094 | Test Loss: 0.43141\n",
      "Current Time = 12:39:45\n",
      "Epoch: 100 | Loss: 0.18456 | Test Loss: 0.44022\n",
      "Current Time = 12:39:46\n",
      "Epoch: 125 | Loss: 0.09418 | Test Loss: 0.49254\n",
      "Current Time = 12:39:47\n",
      "Epoch: 150 | Loss: 0.07367 | Test Loss: 0.50446\n",
      "Current Time = 12:39:48\n",
      "Epoch: 175 | Loss: 0.03257 | Test Loss: 0.54324\n",
      "Current Time = 12:39:49\n",
      "2 2 1 0.8477424031310998\n",
      "Epoch: 0 | Loss: 4.94398 | Test Loss: 4.87618\n",
      "Current Time = 12:39:50\n",
      "Epoch: 25 | Loss: 0.82746 | Test Loss: 0.81243\n",
      "Current Time = 12:39:52\n",
      "Epoch: 50 | Loss: 0.44122 | Test Loss: 0.54733\n",
      "Current Time = 12:39:53\n",
      "Epoch: 75 | Loss: 0.25747 | Test Loss: 0.38498\n",
      "Current Time = 12:39:54\n",
      "Epoch: 100 | Loss: 0.16285 | Test Loss: 0.36718\n",
      "Current Time = 12:39:55\n",
      "Epoch: 125 | Loss: 0.10107 | Test Loss: 0.40667\n",
      "Current Time = 12:39:56\n",
      "Epoch: 150 | Loss: 0.06558 | Test Loss: 0.43576\n",
      "Current Time = 12:39:57\n",
      "Epoch: 175 | Loss: 0.04228 | Test Loss: 0.44915\n",
      "Current Time = 12:39:59\n",
      "2 2 2 0.9352652962928192\n",
      "2 2 0.8915038497119595 0.043761446580859675\n",
      "Epoch: 0 | Loss: 83.88748 | Test Loss: 91.86253\n",
      "Current Time = 12:40:00\n",
      "Epoch: 25 | Loss: 47.72590 | Test Loss: 50.01348\n",
      "Current Time = 12:40:01\n",
      "Epoch: 50 | Loss: 5.48187 | Test Loss: 27.29288\n",
      "Current Time = 12:40:02\n",
      "Epoch: 75 | Loss: 1.62293 | Test Loss: 18.66430\n",
      "Current Time = 12:40:03\n",
      "Epoch: 100 | Loss: 0.54606 | Test Loss: 14.93839\n",
      "Current Time = 12:40:05\n",
      "Epoch: 125 | Loss: 0.60134 | Test Loss: 12.51856\n",
      "Current Time = 12:40:06\n",
      "Epoch: 150 | Loss: 0.30153 | Test Loss: 13.21570\n",
      "Current Time = 12:40:07\n",
      "Epoch: 175 | Loss: 0.24177 | Test Loss: 12.94273\n",
      "Current Time = 12:40:08\n",
      "2 3 1 0.9331004561093654\n",
      "Epoch: 0 | Loss: 96.16038 | Test Loss: 19.79119\n",
      "Current Time = 12:40:09\n",
      "Epoch: 25 | Loss: 28.52751 | Test Loss: 15.32416\n",
      "Current Time = 12:40:10\n",
      "Epoch: 50 | Loss: 5.67958 | Test Loss: 9.55166\n",
      "Current Time = 12:40:12\n",
      "Epoch: 75 | Loss: 1.21172 | Test Loss: 4.73343\n",
      "Current Time = 12:40:13\n",
      "Epoch: 100 | Loss: 0.51441 | Test Loss: 3.43559\n",
      "Current Time = 12:40:14\n",
      "Epoch: 125 | Loss: 0.68369 | Test Loss: 2.76907\n",
      "Current Time = 12:40:15\n",
      "Epoch: 150 | Loss: 0.28466 | Test Loss: 2.87736\n",
      "Current Time = 12:40:16\n",
      "Epoch: 175 | Loss: 0.21228 | Test Loss: 3.02946\n",
      "Current Time = 12:40:18\n",
      "2 3 2 0.9399970073998931\n",
      "2 3 0.9365487317546293 0.003448275645263843\n",
      "Epoch: 0 | Loss: 4.13364 | Test Loss: 3.92560\n",
      "Current Time = 12:40:19\n",
      "Epoch: 25 | Loss: 1.28928 | Test Loss: 1.95367\n",
      "Current Time = 12:40:20\n",
      "Epoch: 50 | Loss: 0.41465 | Test Loss: 0.93059\n",
      "Current Time = 12:40:21\n",
      "Epoch: 75 | Loss: 0.28230 | Test Loss: 0.85307\n",
      "Current Time = 12:40:22\n",
      "Epoch: 100 | Loss: 0.23579 | Test Loss: 0.80283\n",
      "Current Time = 12:40:23\n",
      "Epoch: 125 | Loss: 0.21438 | Test Loss: 0.93097\n",
      "Current Time = 12:40:25\n",
      "Epoch: 150 | Loss: 0.15761 | Test Loss: 0.94084\n",
      "Current Time = 12:40:26\n",
      "Epoch: 175 | Loss: 0.27927 | Test Loss: 1.11246\n",
      "Current Time = 12:40:27\n",
      "3 1 1 0.8074141905141773\n",
      "Epoch: 0 | Loss: 3.56826 | Test Loss: 3.91296\n",
      "Current Time = 12:40:28\n",
      "Epoch: 25 | Loss: 2.51913 | Test Loss: 3.15873\n",
      "Current Time = 12:40:29\n",
      "Epoch: 50 | Loss: 0.54233 | Test Loss: 1.40814\n",
      "Current Time = 12:40:31\n",
      "Epoch: 75 | Loss: 0.30860 | Test Loss: 1.17727\n",
      "Current Time = 12:40:32\n",
      "Epoch: 100 | Loss: 0.25538 | Test Loss: 1.13517\n",
      "Current Time = 12:40:33\n",
      "Epoch: 125 | Loss: 0.21880 | Test Loss: 1.13557\n",
      "Current Time = 12:40:34\n",
      "Epoch: 150 | Loss: 0.16854 | Test Loss: 1.26483\n",
      "Current Time = 12:40:35\n",
      "Epoch: 175 | Loss: 0.11588 | Test Loss: 1.29449\n",
      "Current Time = 12:40:36\n",
      "3 1 2 0.8335333409799073\n",
      "3 1 0.8204737657470422 0.013059575232864995\n",
      "Epoch: 0 | Loss: 95.67178 | Test Loss: 99.72341\n",
      "Current Time = 12:40:38\n",
      "Epoch: 25 | Loss: 17.80932 | Test Loss: 23.64472\n",
      "Current Time = 12:40:39\n",
      "Epoch: 50 | Loss: 2.62498 | Test Loss: 11.64979\n",
      "Current Time = 12:40:40\n",
      "Epoch: 75 | Loss: 1.36364 | Test Loss: 8.17488\n",
      "Current Time = 12:40:41\n",
      "Epoch: 100 | Loss: 0.50836 | Test Loss: 6.87112\n",
      "Current Time = 12:40:42\n",
      "Epoch: 125 | Loss: 0.31296 | Test Loss: 6.47913\n",
      "Current Time = 12:40:43\n",
      "Epoch: 150 | Loss: 0.24087 | Test Loss: 6.11320\n",
      "Current Time = 12:40:45\n",
      "Epoch: 175 | Loss: 0.23421 | Test Loss: 6.03758\n",
      "Current Time = 12:40:46\n",
      "3 2 1 0.9600410258747685\n",
      "Epoch: 0 | Loss: 58.94261 | Test Loss: 92.22779\n",
      "Current Time = 12:40:47\n",
      "Epoch: 25 | Loss: 8.95657 | Test Loss: 11.75390\n",
      "Current Time = 12:40:48\n",
      "Epoch: 50 | Loss: 1.95197 | Test Loss: 8.89223\n",
      "Current Time = 12:40:49\n",
      "Epoch: 75 | Loss: 1.07869 | Test Loss: 7.46586\n",
      "Current Time = 12:40:51\n",
      "Epoch: 100 | Loss: 0.42730 | Test Loss: 6.34835\n",
      "Current Time = 12:40:52\n",
      "Epoch: 125 | Loss: 0.25898 | Test Loss: 6.09169\n",
      "Current Time = 12:40:53\n",
      "Epoch: 150 | Loss: 0.31138 | Test Loss: 5.72511\n",
      "Current Time = 12:40:54\n",
      "Epoch: 175 | Loss: 0.19920 | Test Loss: 6.24249\n",
      "Current Time = 12:40:55\n",
      "3 2 2 0.951088071328235\n",
      "3 2 0.9555645486015018 0.004476477273266721\n",
      "Epoch: 0 | Loss: 8834.04395 | Test Loss: 17898.99414\n",
      "Current Time = 12:40:57\n",
      "Epoch: 25 | Loss: 6125.17871 | Test Loss: 13903.03418\n",
      "Current Time = 12:40:58\n",
      "Epoch: 50 | Loss: 608.30353 | Test Loss: 12514.85938\n",
      "Current Time = 12:40:59\n",
      "Epoch: 75 | Loss: 170.19078 | Test Loss: 11421.57422\n",
      "Current Time = 12:41:00\n",
      "Epoch: 100 | Loss: 50.75938 | Test Loss: 9804.56641\n",
      "Current Time = 12:41:01\n",
      "Epoch: 125 | Loss: 64.52095 | Test Loss: 9373.22168\n",
      "Current Time = 12:41:02\n",
      "Epoch: 150 | Loss: 11.17578 | Test Loss: 9507.29297\n",
      "Current Time = 12:41:04\n",
      "Epoch: 175 | Loss: 6.65079 | Test Loss: 9421.00098\n",
      "Current Time = 12:41:05\n",
      "3 3 1 0.8234123690285533\n",
      "Epoch: 0 | Loss: 3599.57397 | Test Loss: 1945.66248\n",
      "Current Time = 12:41:06\n",
      "Epoch: 25 | Loss: 2216.15381 | Test Loss: 1526.72668\n",
      "Current Time = 12:41:07\n",
      "Epoch: 50 | Loss: 225.91138 | Test Loss: 648.64630\n",
      "Current Time = 12:41:08\n",
      "Epoch: 75 | Loss: 29.61010 | Test Loss: 338.24814\n",
      "Current Time = 12:41:10\n",
      "Epoch: 100 | Loss: 10.96869 | Test Loss: 308.33997\n",
      "Current Time = 12:41:11\n",
      "Epoch: 125 | Loss: 4.67701 | Test Loss: 302.61951\n",
      "Current Time = 12:41:12\n",
      "Epoch: 150 | Loss: 3.19137 | Test Loss: 283.91693\n",
      "Current Time = 12:41:13\n",
      "Epoch: 175 | Loss: 3.22271 | Test Loss: 273.91055\n",
      "Current Time = 12:41:14\n",
      "3 3 2 0.9013690234062937\n",
      "3 3 0.8623906962174235 0.03897832718887018\n"
     ]
    }
   ],
   "source": [
    "for model1 in range(1,4):\n",
    "    for model2 in range(1,4):\n",
    "        dcor_list=[]\n",
    "        for t in range(1,3):\n",
    "            x_train=pd.read_csv(\"./data-prelim/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/x_train_\" + str(t) + \".csv\")\n",
    "            x_train=x_train.drop('Unnamed: 0', axis=1)\n",
    "            y_train=pd.read_csv(\"./data-prelim/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/y_train_\" + str(t) + \".csv\")\n",
    "            y_train=y_train.drop('Unnamed: 0', axis=1)\n",
    "            x_test=pd.read_csv(\"./data-prelim/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/x_test_\" + str(t) + \".csv\")\n",
    "            x_test=x_test.drop('Unnamed: 0', axis=1)\n",
    "            y_test=pd.read_csv(\"./data-prelim/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/y_test_\" + str(t) + \".csv\")\n",
    "            y_test=y_test.drop('Unnamed: 0', axis=1)\n",
    "            z_test=pd.read_csv(\"./data-prelim/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/z_test_\" + str(t) + \".csv\")\n",
    "            z_test=z_test.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "            n=x_train.shape[0]\n",
    "            p=x_train.shape[1]\n",
    "\n",
    "\n",
    "            x_train = torch.tensor(x_train.values).to(torch.float)\n",
    "            x_test = torch.tensor(x_test.values).to(torch.float)\n",
    "            if m==1:\n",
    "                y_train = torch.tensor(y_train.values).to(torch.float)\n",
    "                y_test = torch.tensor(y_test.values).to(torch.float)\n",
    "            else:\n",
    "                y_trans_train = (y_train - y_train.mean()) / y_train.std()\n",
    "                y_trans_test = (y_test - y_train.mean()) / y_train.std()\n",
    "                for i in range(2,m+1):\n",
    "                    y_train_intermediate=y_train**i/math.factorial(i)\n",
    "                    y_test_intermediate=y_test**i/math.factorial(i)\n",
    "                    y_test_intermediate = (y_test_intermediate - y_train_intermediate.mean()) / y_train_intermediate.std()\n",
    "                    y_train_intermediate = (y_train_intermediate - y_train_intermediate.mean()) / y_train_intermediate.std()\n",
    "                    y_trans_train = np.concatenate((y_trans_train,y_train_intermediate), axis=1)\n",
    "                    y_trans_test = np.concatenate((y_trans_test,y_test_intermediate), axis=1)\n",
    "                y_train = torch.tensor(y_trans_train).to(torch.float)\n",
    "                y_test = torch.tensor(y_trans_test).to(torch.float)\n",
    "\n",
    "\n",
    "            mse_loss = nn.MSELoss()\n",
    "            class nn_dr_reg_model(nn.Module):\n",
    "                def __init__(self, input_features, output_features, dim_red_features, hidden_units_d, hidden_units_e, dim_red_layers, ens_reg_layers):\n",
    "                    super().__init__()\n",
    "                    model_dim_red=[]\n",
    "                    model_dim_red.append(nn.Linear(in_features=input_features, \n",
    "                                                out_features=hidden_units_d))\n",
    "                    model_dim_red.append(nn.ReLU())\n",
    "                    for i in range(1,dim_red_layers):\n",
    "                        model_dim_red.append(nn.Linear(in_features=hidden_units_d, \n",
    "                                                    out_features=hidden_units_d))\n",
    "                        model_dim_red.append(nn.ReLU())\n",
    "                    model_dim_red.append(nn.Linear(in_features=hidden_units_d, \n",
    "                                                out_features=dim_red_features))\n",
    "                    self.dim_red_layer_stack = nn.Sequential(*model_dim_red)\n",
    "\n",
    "                    model_ens_reg=[]\n",
    "                    model_ens_reg.append(nn.Linear(in_features=dim_red_features, out_features=hidden_units_e))\n",
    "                    model_ens_reg.append(nn.ReLU())\n",
    "                    for i in range(1,ens_reg_layers):\n",
    "                        model_ens_reg.append(nn.Linear(in_features=hidden_units_e, out_features=hidden_units_e))\n",
    "                        model_ens_reg.append(nn.ReLU())\n",
    "                    model_ens_reg.append(nn.Linear(in_features=hidden_units_e, out_features=output_features))\n",
    "                    self.ens_reg_layer_stack = nn.Sequential(*model_ens_reg)\n",
    "\n",
    "                def forward(self, x):\n",
    "                    suff_predictor = self.dim_red_layer_stack(x)\n",
    "                    ens_output = self.ens_reg_layer_stack(suff_predictor)\n",
    "                    return ens_output, suff_predictor\n",
    "\n",
    "\n",
    "            model_nn = nn_dr_reg_model(input_features=p, \n",
    "                                    output_features=m, \n",
    "                                    dim_red_features=res_d, \n",
    "                                    hidden_units_d=r1,\n",
    "                                    hidden_units_e=r2,\n",
    "                                    dim_red_layers=l1, \n",
    "                                    ens_reg_layers=l2\n",
    "                                    ).to(device)\n",
    "            model_nn\n",
    "            optimizer = torch.optim.Adam(model_nn.parameters(), \n",
    "                                        lr=0.001)\n",
    "            epochs = 200\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "            x_test = x_test.to(device)\n",
    "            for epoch in range(epochs):\n",
    "                ### Training\n",
    "                model_nn.train()\n",
    "                y_pred_train, y_suff_train = model_nn(x_train) \n",
    "                loss = mse_loss(y_pred_train, y_train) \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                ### Testing\n",
    "                model_nn.eval()\n",
    "                y_pred_test, y_suff_test = model_nn(x_test)\n",
    "                loss_test = mse_loss(y_pred_test, y_test) \n",
    "                dcor_test = dcor.distance_correlation(np.float64(y_suff_test.detach().numpy()),np.float64(z_test))\n",
    "\n",
    "                if epoch % 25 == 0:\n",
    "                    print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Test Loss: {loss_test:.5f}\")\n",
    "                    now = datetime.now()\n",
    "                    current_time = now.strftime(\"%H:%M:%S\")\n",
    "                    print(\"Current Time =\", current_time)\n",
    "            model_nn.eval()\n",
    "            with torch.inference_mode():\n",
    "                y_pred_test, y_suff_test = model_nn(x_test)\n",
    "            y_suff_test=y_suff_test.numpy()\n",
    "            if res_d==1:\n",
    "                dcor_current=dcor.distance_correlation(np.float64(y_suff_test),np.float64(z_test.to_numpy()),method=\"naive\")\n",
    "            elif res_d==2:\n",
    "                dcor_current=[dcor.distance_correlation(np.float64(y_suff_test),np.float64(z_test.to_numpy()),method=\"naive\"),\n",
    "                              dcor.distance_correlation(np.float64(y_suff_test),np.float64(z_test.to_numpy()[:,0]),method=\"naive\"),\n",
    "                              dcor.distance_correlation(np.float64(y_suff_test),np.float64(z_test.to_numpy()[:,1]),method=\"naive\")]\n",
    "            dcor_list.append(dcor_current)\n",
    "            print(model1, model2, t, dcor_current)\n",
    "        dcor_list_df=pd.DataFrame(dcor_list)\n",
    "        #dcor_list_df.to_csv(\"./results-BENN-unified-std/result-\" + str(model1) + \"-\" + str(model2) + \"-\" + str(m) + \"-\" + str(n) + \".csv\")\n",
    "        print(model1, model2, np.mean(dcor_list), np.std(dcor_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch_conda",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
