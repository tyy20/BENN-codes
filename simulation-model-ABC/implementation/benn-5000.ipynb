{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7484cc-6b31-4d27-b17b-b3a89569d6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "\n",
    "import dcor\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d636a47a-cebf-438a-b29b-ba467c0900eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Running BENN\")\n",
    "parser.add_argument('--model1', default=1, type = int, help = 'model1')\n",
    "parser.add_argument('--model2', default=1, type = int, help = 'model2')\n",
    "args = parser.parse_args()\n",
    "model1 = args.model1\n",
    "model2 = args.model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50359073-4520-42d2-bcc6-63ce3e3ca145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0c665f-c218-4553-96f8-80fd29f1114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 5.39651 | Test Loss: 6.68402 | Dcor: 0.23035\n",
      "Current Time = 23:12:35\n",
      "Epoch: 25 | Loss: 1.34222 | Test Loss: 1.55090 | Dcor: 0.85904\n",
      "Current Time = 23:12:37\n",
      "Epoch: 50 | Loss: 0.47786 | Test Loss: 0.86121 | Dcor: 0.91940\n",
      "Current Time = 23:12:38\n",
      "Epoch: 75 | Loss: 0.37094 | Test Loss: 0.70151 | Dcor: 0.93534\n",
      "Current Time = 23:12:40\n",
      "Epoch: 100 | Loss: 0.24297 | Test Loss: 0.60602 | Dcor: 0.96894\n",
      "Current Time = 23:12:41\n",
      "Epoch: 125 | Loss: 0.17260 | Test Loss: 0.55817 | Dcor: 0.97079\n",
      "Current Time = 23:12:43\n",
      "Epoch: 150 | Loss: 0.12167 | Test Loss: 0.59415 | Dcor: 0.96285\n",
      "Current Time = 23:12:44\n",
      "Epoch: 175 | Loss: 0.08803 | Test Loss: 0.61895 | Dcor: 0.95473\n",
      "Current Time = 23:12:46\n",
      "2 2 1 0.9479520826329603\n",
      "Epoch: 0 | Loss: 4.53779 | Test Loss: 4.82875 | Dcor: 0.06764\n",
      "Current Time = 23:12:47\n",
      "Epoch: 25 | Loss: 1.14189 | Test Loss: 1.14178 | Dcor: 0.79286\n",
      "Current Time = 23:12:49\n",
      "Epoch: 50 | Loss: 0.43588 | Test Loss: 0.63095 | Dcor: 0.88467\n",
      "Current Time = 23:12:50\n",
      "Epoch: 75 | Loss: 0.28846 | Test Loss: 0.48684 | Dcor: 0.85946\n",
      "Current Time = 23:12:52\n",
      "Epoch: 100 | Loss: 0.18072 | Test Loss: 0.46931 | Dcor: 0.84506\n",
      "Current Time = 23:12:53\n",
      "Epoch: 125 | Loss: 0.11984 | Test Loss: 0.48270 | Dcor: 0.84473\n",
      "Current Time = 23:12:55\n",
      "Epoch: 150 | Loss: 0.11805 | Test Loss: 0.65508 | Dcor: 0.83977\n",
      "Current Time = 23:12:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n=5000\n",
    "\n",
    "dcor_list=[]\n",
    "for t in range(1,101):\n",
    "    x_train=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/x_train_\" + str(t) + \".csv\")\n",
    "    x_train=x_train.drop('Unnamed: 0', axis=1)\n",
    "    y_train=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/y_train_\" + str(t) + \".csv\")\n",
    "    y_train=y_train.drop('Unnamed: 0', axis=1)\n",
    "    x_test=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/x_test_\" + str(t) + \".csv\")\n",
    "    x_test=x_test.drop('Unnamed: 0', axis=1)\n",
    "    y_test=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/y_test_\" + str(t) + \".csv\")\n",
    "    y_test=y_test.drop('Unnamed: 0', axis=1)\n",
    "    z_test=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/z_test_\" + str(t) + \".csv\")\n",
    "    z_test=z_test.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "\n",
    "    n=x_train.shape[0]\n",
    "    p=x_train.shape[1]\n",
    "    res_d=1\n",
    "    m=2\n",
    "    x_train = torch.tensor(x_train.values).to(torch.float)\n",
    "    y_train = torch.tensor(y_train.values).to(torch.float)\n",
    "    x_test = torch.tensor(x_test.values).to(torch.float)\n",
    "    y_test = torch.tensor(y_test.values).to(torch.float)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    class nn_dr_reg_model(nn.Module):\n",
    "        def __init__(self, input_features, output_features, dim_red_features, hidden_units_d, hidden_units_e, dim_red_layers, ens_reg_layers):\n",
    "            super().__init__()\n",
    "            model_dim_red=[]\n",
    "            model_dim_red.append(nn.Linear(in_features=input_features, \n",
    "                                        out_features=hidden_units_d))\n",
    "            model_dim_red.append(nn.ReLU())\n",
    "            for i in range(1,dim_red_layers):\n",
    "                model_dim_red.append(nn.Linear(in_features=hidden_units_d, \n",
    "                                            out_features=hidden_units_d))\n",
    "                model_dim_red.append(nn.ReLU())\n",
    "            model_dim_red.append(nn.Linear(in_features=hidden_units_d, \n",
    "                                        out_features=dim_red_features))\n",
    "            self.dim_red_layer_stack = nn.Sequential(*model_dim_red)\n",
    "\n",
    "            model_ens_reg=[]\n",
    "            model_ens_reg.append(nn.Linear(in_features=dim_red_features, out_features=hidden_units_e))\n",
    "            model_ens_reg.append(nn.ReLU())\n",
    "            for i in range(1,ens_reg_layers):\n",
    "                model_ens_reg.append(nn.Linear(in_features=hidden_units_e, out_features=hidden_units_e))\n",
    "                model_ens_reg.append(nn.ReLU())\n",
    "            model_ens_reg.append(nn.Linear(in_features=hidden_units_e, out_features=output_features))\n",
    "            self.ens_reg_layer_stack = nn.Sequential(*model_ens_reg)\n",
    "\n",
    "        def forward(self, x):\n",
    "            suff_predictor = self.dim_red_layer_stack(x)\n",
    "            ens_output = self.ens_reg_layer_stack(suff_predictor)\n",
    "            return ens_output, suff_predictor\n",
    "\n",
    "\n",
    "        \n",
    "    model_nn = nn_dr_reg_model(input_features=p, \n",
    "                            output_features=1, \n",
    "                            dim_red_features=res_d, \n",
    "                            hidden_units_d=300,\n",
    "                            hidden_units_e=300,\n",
    "                            dim_red_layers=5, \n",
    "                            ens_reg_layers=5\n",
    "                            ).to(device)\n",
    "    model_nn\n",
    "    optimizer = torch.optim.Adam(model_nn.parameters(), \n",
    "                                lr=0.001)\n",
    "    epochs = 200\n",
    "    x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "    x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        ### Training\n",
    "        model_nn.train()\n",
    "        y_pred_train, y_suff_train = model_nn(x_train) \n",
    "        loss = mse_loss(y_pred_train, y_train) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ### Testing\n",
    "        model_nn.eval()\n",
    "        y_pred_test, y_suff_test = model_nn(x_test)\n",
    "        loss_test = mse_loss(y_pred_test, y_test) \n",
    "        dcor_test = dcor.distance_correlation(np.float64(y_suff_test.detach().numpy()),np.float64(z_test))\n",
    "\n",
    "        if epoch % 25 == 0:\n",
    "            print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Test Loss: {loss_test:.5f} | Dcor: {dcor_test:.5f}\")\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print(\"Current Time =\", current_time)\n",
    "    model_nn.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred_test, y_suff_test = model_nn(x_test)\n",
    "    y_suff_test=y_suff_test.numpy()\n",
    "    dcor_current=dcor.distance_correlation(np.float64(y_suff_test),np.float64(z_test.to_numpy()),method=\"naive\")\n",
    "    dcor_list.append(dcor_current)\n",
    "    print(model1, model2, t, dcor_current)\n",
    "dcor_list_df=pd.DataFrame(dcor_list)\n",
    "dcor_list_df.to_csv(\"./results-BENN/result-\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \".csv\")\n",
    "print(model1, model2, np.mean(dcor_list), np.std(dcor_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch_conda",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
