{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7484cc-6b31-4d27-b17b-b3a89569d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "\n",
    "import dcor\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os \n",
    "\n",
    "import time\n",
    "from time import process_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d636a47a-cebf-438a-b29b-ba467c0900eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## command-line arguments\n",
    "parser = argparse.ArgumentParser(description=\"Running BENN\")\n",
    "parser.add_argument('--model1', default=4, type = int, help = 'model1') ## model label 1\n",
    "parser.add_argument('--model2', default=1, type = int, help = 'model2') ## model label 2\n",
    "parser.add_argument('--n', default=5000, type = int, help = 'n') ## sample size\n",
    "parser.add_argument('--m', default=1000, type = int, help = 'm') ## number of ensemble transformations\n",
    "parser.add_argument('--l1', default=2, type = int, help = 'l1') ## depth of dimension reduction network\n",
    "parser.add_argument('--l2', default=1, type = int, help = 'l2') ## depth of ensemble regression network\n",
    "parser.add_argument('--r1', default=50, type = int, help = 'r1') ## width of dimension reduction network\n",
    "parser.add_argument('--r2', default=2000, type = int, help = 'r2') ## width of ensemble regression network\n",
    "parser.add_argument('--d', default=2, type = int, help = 'd') ## dimension of belt (sufficient predictor)\n",
    "parser.add_argument('--t', default=3, type = int, help = 't') ## index of experiment\n",
    "args = parser.parse_args() ## replace by parser.parse_args([]) to use the default command-line arguments\n",
    "model1 = args.model1\n",
    "model2 = args.model2\n",
    "n = args.n\n",
    "m = args.m\n",
    "l1 = args.l1\n",
    "l2 = args.l2\n",
    "r1 = args.r1\n",
    "r2 = args.r2\n",
    "res_d = args.d\n",
    "t = args.t\n",
    "print(model1, model2, n, m, l1, l2, r1, r2, res_d, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928398fd-e16f-4f9b-8bfe-d5e1856470dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting directories (path requires modification)\n",
    "directory=\"./results-BENN-unified-std/result-\" + str(model1) + \"-\" + str(model2) + \"-\" + str(m) + \"-\" + str(n)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50359073-4520-42d2-bcc6-63ce3e3ca145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd3b09-e12c-4172-973e-11a56a2d1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the dataset (path requires modification)\n",
    "x_train=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/x_train_\" + str(t) + \".csv\")\n",
    "x_train=x_train.drop('Unnamed: 0', axis=1)\n",
    "y_train=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/y_train_\" + str(t) + \".csv\")\n",
    "y_train=y_train.drop('Unnamed: 0', axis=1)\n",
    "x_test=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/x_test_\" + str(t) + \".csv\")\n",
    "x_test=x_test.drop('Unnamed: 0', axis=1)\n",
    "y_test=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/y_test_\" + str(t) + \".csv\")\n",
    "y_test=y_test.drop('Unnamed: 0', axis=1)\n",
    "y_train_original=y_train\n",
    "y_test_original=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d077a4-9916-4329-805f-200ec1c0eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## z_test is the true sufficient predictor in the simulations for evaluation purposes\n",
    "## remove the lines for z_test if no evaluation is needed\n",
    "z_test=pd.read_csv(\"./data/model\" + str(model1) + \"-\" + str(model2) + \"-\" + str(n) + \"/z_test_\" + str(t) + \".csv\")\n",
    "z_test=z_test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e195dddf-f1f1-4bc0-b3e4-5114ae6ca8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "x_test=x_test.to_numpy()\n",
    "y_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb317d-2323-4e45-af64-e45f7c1bcea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_start = time.time() \n",
    "t2_start = process_time()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2dfad7ab-acb5-446f-bdb1-c5b7c22881fc",
   "metadata": {},
   "source": [
    "perform kernel transformations on Y\n",
    "- random generate m values of y*\n",
    "- apply Gaussian kernel k(y_i,y*) with each y* for each sample y_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3660dd-41f6-4052-9018-daef5327adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_func(bw, y1, y2):\n",
    "    return math.exp(-((y1-y2)/bw)**2/2)\n",
    "\n",
    "y_list=np.random.uniform(low=y_train.mean()-2*y_train.std(),\n",
    "                         high=y_train.mean()+2*y_train.std(),\n",
    "                         size=m)\n",
    "bw=y_train.std()\n",
    "\n",
    "y_trans_train=[]\n",
    "for i in range(y_train.shape[0]):\n",
    "    y_trans_current=[]\n",
    "    for j in range(m):\n",
    "        y_trans_current.append(kernel_func(bw,y_list[j],y_train[i][0]))\n",
    "    y_trans_train.append(y_trans_current)\n",
    "y_trans_train=np.array(y_trans_train)\n",
    "y_trans_test=[]\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_trans_current=[]\n",
    "    for j in range(m):\n",
    "        y_trans_current.append(kernel_func(bw,y_list[j],y_test[i][0]))\n",
    "    y_trans_test.append(y_trans_current)\n",
    "y_trans_test=np.array(y_trans_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e290060-c5fc-48de-96ef-818f4b860395",
   "metadata": {},
   "source": [
    "define the class of neural network\n",
    "- two parts: \n",
    "    - dimension reduction network \n",
    "    - ensemble regression network\n",
    "- outputs of both parts are returned: \n",
    "    - dimension reduction part for sufficient predictor\n",
    "    - ensemble regression prat for loss calculation and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e3b6f-eacf-40f8-9d9f-9ca7bface9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "class nn_dr_reg_model(nn.Module):\n",
    "    def __init__(self, input_features, output_features, dim_red_features, hidden_units_d, hidden_units_e, dim_red_layers, ens_reg_layers):\n",
    "        super().__init__()\n",
    "        ## dimension reduction network\n",
    "        model_dim_red=[]\n",
    "        model_dim_red.append(nn.Linear(in_features=input_features, \n",
    "                                    out_features=hidden_units_d))\n",
    "        model_dim_red.append(nn.ReLU())\n",
    "        for i in range(1,dim_red_layers):\n",
    "            model_dim_red.append(nn.Linear(in_features=hidden_units_d, \n",
    "                                        out_features=hidden_units_d))\n",
    "            model_dim_red.append(nn.ReLU())\n",
    "        model_dim_red.append(nn.Linear(in_features=hidden_units_d, \n",
    "                                    out_features=dim_red_features))\n",
    "        self.dim_red_layer_stack = nn.Sequential(*model_dim_red)\n",
    "\n",
    "        ## ensemble regression network\n",
    "        model_ens_reg=[]\n",
    "        model_ens_reg.append(nn.Linear(in_features=dim_red_features, out_features=hidden_units_e))\n",
    "        model_ens_reg.append(nn.ReLU())\n",
    "        for i in range(1,ens_reg_layers):\n",
    "            model_ens_reg.append(nn.Linear(in_features=hidden_units_e, out_features=hidden_units_e))\n",
    "            model_ens_reg.append(nn.ReLU())\n",
    "        model_ens_reg.append(nn.Linear(in_features=hidden_units_e, out_features=output_features))\n",
    "        self.ens_reg_layer_stack = nn.Sequential(*model_ens_reg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        suff_predictor = self.dim_red_layer_stack(x)\n",
    "        ens_output = self.ens_reg_layer_stack(suff_predictor)\n",
    "        return ens_output, suff_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b84e7-6715-41c5-8ffd-14cc79804d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=x_train.shape[0]\n",
    "p=x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab10d8-4352-478d-b11c-9d28e817c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train).to(torch.float)\n",
    "x_test = torch.tensor(x_test).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1cee52-8dba-4a07-b83b-17616c2b62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_trans_train).to(torch.float)\n",
    "y_test = torch.tensor(y_trans_test).to(torch.float)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac41cbfb-0ecb-4a97-a160-e01c89d46487",
   "metadata": {},
   "source": [
    "neural network structures\n",
    "- input dimension: p\n",
    "- dimension of belt (sufficient predictors): res_d\n",
    "- output dimension: m\n",
    "- depth of dimension reduction network: l1\n",
    "- depth of ensemble regression network: l2\n",
    "- width of dimension reduction network: r1\n",
    "- width of ensemble regression network: r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcecf6a-d6bc-48c5-88ae-4b061aef746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = nn_dr_reg_model(input_features=p, \n",
    "                        output_features=m, \n",
    "                        dim_red_features=res_d, \n",
    "                        hidden_units_d=r1,\n",
    "                        hidden_units_e=r2,\n",
    "                        dim_red_layers=l1, \n",
    "                        ens_reg_layers=l2\n",
    "                        ).to(device)\n",
    "model_nn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a17e4e90-5ec3-46cd-a58b-de884fb62e7e",
   "metadata": {},
   "source": [
    "train the neural network using Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db139c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_nn.parameters(), \n",
    "                            lr=0.001,weight_decay=0)\n",
    "epochs = 150   ## number of epoches can be modified based on loss changes\n",
    "x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_nn.train()\n",
    "    y_pred_train, y_suff_train = model_nn(x_train) \n",
    "    loss = mse_loss(y_pred_train, y_train) \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    ### Testing\n",
    "    model_nn.eval()\n",
    "    y_pred_test, y_suff_test = model_nn(x_test)\n",
    "    loss_test = mse_loss(y_pred_test, y_test) \n",
    "    # remove the following line if there is no z_test or no evaluation is required\n",
    "    dcor_test = dcor.distance_correlation(np.float64(y_suff_test.detach().numpy()),np.float64(z_test)) \n",
    "\n",
    "    if epoch % 25 == 24:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Test Loss: {loss_test:.5f}\")\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(\"Current Time =\", current_time)\n",
    "model_nn.eval()\n",
    "with torch.inference_mode():\n",
    "    y_pred_test, y_suff_test = model_nn(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0931026-1c6d-4f05-801a-241dd5b42fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_stop = time.time() \n",
    "t2_stop = process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c79dc-9b90-46bd-b502-37dd140bf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save sufficient predictors (path requires modification)\n",
    "y_suff_test=y_suff_test.numpy()\n",
    "y_suff_test_df=pd.DataFrame(y_suff_test)\n",
    "y_suff_test_df.to_csv(\"./results-BENN-unified-std/result-\" + str(model1) + \"-\" + str(model2) + \"-\" + str(m) + \"-\" + str(n) + \"/y_suff_\" + str(t) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfb117-0781-4f34-9023-1f16fc3dc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save running times (path requires modification)\n",
    "time_use=[t1_stop-t1_start,t2_stop-t2_start]\n",
    "time_use_df=pd.DataFrame(time_use)\n",
    "time_use_df.to_csv(\"./results-BENN-unified-std/result-\" + str(model1) + \"-\" + str(model2) + \"-\" + str(m) + \"-\" + str(n) + \"/time_\" + str(t) + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch_conda",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
